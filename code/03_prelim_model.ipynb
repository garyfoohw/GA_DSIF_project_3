{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1522b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.corpus import stopwords\n",
    "from utils import run_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da05d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the nail in the coffin for the idea of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’m closeted, always been, and always will be....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the fifa world cup in qatar should be a remind...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we moved from the dc metro area last year to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they spend so much time focusing on arbitrary ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>if jesus died for our sins, what's keeping u f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10079</th>\n",
       "      <td>hello everybody it may seem like a dumb questi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10080</th>\n",
       "      <td>today's readings: 1 corinthian 1:4-8 &amp;gt;i tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10081</th>\n",
       "      <td>i don't propose this question in the sense of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10082</th>\n",
       "      <td>i'd like to preface this by saying that i've n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10083 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post  label\n",
       "0      this is the nail in the coffin for the idea of...      0\n",
       "1      i’m closeted, always been, and always will be....      0\n",
       "2      the fifa world cup in qatar should be a remind...      0\n",
       "3      we moved from the dc metro area last year to t...      0\n",
       "4      they spend so much time focusing on arbitrary ...      0\n",
       "...                                                  ...    ...\n",
       "10078  if jesus died for our sins, what's keeping u f...      1\n",
       "10079  hello everybody it may seem like a dumb questi...      1\n",
       "10080  today's readings: 1 corinthian 1:4-8 &gt;i tha...      1\n",
       "10081  i don't propose this question in the sense of ...      1\n",
       "10082  i'd like to preface this by saying that i've n...      1\n",
       "\n",
       "[10083 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load source data\n",
    "\n",
    "path=\"../data/combined.pickle\"\n",
    "\n",
    "try:\n",
    "    with open(path,'rb') as handle:\n",
    "        pickleload=pickle.load(handle)\n",
    "except FileNotFoundError as e:\n",
    "    e.strerror = \"Pls run 01_scrape_reddit first to pull the data and 02_EDA to merge data.\"\n",
    "    raise e\n",
    "\n",
    "df=pd.DataFrame(pickleload)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e794af",
   "metadata": {},
   "source": [
    "### Prepare the dataset, pass through `CountVectorizer` and look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc72b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['post']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cba701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        this is the nail in the coffin for the idea of...\n",
       "1        i’m closeted, always been, and always will be....\n",
       "2        the fifa world cup in qatar should be a remind...\n",
       "3        we moved from the dc metro area last year to t...\n",
       "4        they spend so much time focusing on arbitrary ...\n",
       "                               ...                        \n",
       "10078    if jesus died for our sins, what's keeping u f...\n",
       "10079    hello everybody it may seem like a dumb questi...\n",
       "10080    today's readings: 1 corinthian 1:4-8 &gt;i tha...\n",
       "10081    i don't propose this question in the sense of ...\n",
       "10082    i'd like to preface this by saying that i've n...\n",
       "Name: post, Length: 10083, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39721d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 33838\n",
      "Features:\n",
      "['00' '000' '000ish' ... '𝚖𝚊𝚔𝚎𝚛' '𝚗𝚘' '𝚠𝚊𝚝𝚌𝚑']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(stop_words=stopwords.words(\"english\"))\n",
    "X=df['post']\n",
    "\n",
    "cv.fit_transform(X)\n",
    "feat_list=cv.get_feature_names_out()\n",
    "#number of features\n",
    "print(f\"Number of features: {len(feat_list)}\")\n",
    "print(\"Features:\")\n",
    "print(feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a64e3",
   "metadata": {},
   "source": [
    "It is interesting to note that the list of features is 35k long, and have a list of numbers.  \n",
    "Let's remove the numbers and see what remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4603d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 32819\n",
      "Features:\n",
      "['aa' 'aaaaaaamen' 'aaaand' ... '𝚖𝚊𝚔𝚎𝚛' '𝚗𝚘' '𝚠𝚊𝚝𝚌𝚑']\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(stop_words=stopwords.words(\"english\"),token_pattern=\"[^\\W\\d_]+\")\n",
    "X=df['post']\n",
    "\n",
    "cv.fit_transform(X)\n",
    "feat_list=cv.get_feature_names_out()\n",
    "#number of features\n",
    "print(f\"Number of features: {len(feat_list)}\")\n",
    "print(\"Features:\")\n",
    "print(feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17434c",
   "metadata": {},
   "source": [
    "The list of feature shortens to 34k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17328fec",
   "metadata": {},
   "source": [
    "## Run Preliminary Classification on Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6baec",
   "metadata": {},
   "source": [
    "and run RandomizedSearchCV at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e4363",
   "metadata": {},
   "source": [
    "Note that we use ROC AUC as the indicator instead of the usual Accuracy.  \n",
    "ROC AUC is a more comprehensive indicator as it factors both true positive rate (TPR) and false positive rate (FPR).\n",
    "ROC AUC is also a suitable candidate given that the labels are split equally i.e. not unbalanced.  \n",
    "This is as compared to conventional accuracy which simply considers correctly predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6990f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Running classifier: NaiveBayes =======\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best parameters and accuracy\n",
      "{'cvec__min_df': 0.05, 'cvec__max_features': 3000, 'cvec__max_df': 0.8}\n",
      "ROC AUC with CV=5: 0.8118935063167214\n"
     ]
    }
   ],
   "source": [
    "classifiers_list=[\n",
    "    {\n",
    "        'cls':MultinomialNB(),\n",
    "        'name':'NaiveBayes',\n",
    "        'float_params':{\n",
    "            'cvec__max_features':range(3000,4000,100),\n",
    "            'cvec__max_df':[0.6,0.7,0.8],\n",
    "            'cvec__min_df':[0.05,0.1,0.15],\n",
    "        }\n",
    "    },\n",
    "]\n",
    "run_classifiers(classifiers_list,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3164724",
   "metadata": {},
   "source": [
    "That's a 81% AUC score.  \n",
    "However, `CountVectorizer` gives higher weightage to longer posts, so that is kind of unfair.  \n",
    "In addition, if a word shows up in every post, then in has little significance in classification too.  \n",
    "To resolve this, we apply a Term Frequency, Inverse Document Frequency (TF-IDF) transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebf4620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Running classifier: NaiveBayes =======\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best parameters and accuracy\n",
      "{'tvec__min_df': 0.05, 'tvec__max_features': 3000, 'tvec__max_df': 0.8}\n",
      "ROC AUC with CV=5: 0.8233414478852168\n"
     ]
    }
   ],
   "source": [
    "classifiers_list=[\n",
    "    {\n",
    "        'cls':MultinomialNB(),\n",
    "        'name':'NaiveBayes',\n",
    "        'float_params':{\n",
    "            'tvec__max_features':range(3000,4000,100),\n",
    "            'tvec__max_df':[0.6,0.7,0.8],\n",
    "            'tvec__min_df':[0.05,0.1,0.15],\n",
    "        }\n",
    "    },\n",
    "]\n",
    "run_classifiers(classifiers_list,X,y,tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b09fad",
   "metadata": {},
   "source": [
    "That's a very slight 1% improvement.  \n",
    "Let's try to tune some other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a87b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Running classifier: NaiveBayes =======\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gary\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 4 is smaller than n_iter=30. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters and accuracy\n",
      "{'tvec__use_idf': False, 'tvec__ngram_range': (1, 2)}\n",
      "ROC AUC with CV=5: 0.8257169538682693\n"
     ]
    }
   ],
   "source": [
    "classifiers_list=[\n",
    "    {\n",
    "        'cls':MultinomialNB(),\n",
    "        'name':'NaiveBayes',\n",
    "        'fixed_params':{'min_df': 0.05, 'max_features': 3500, 'max_df': 0.8},\n",
    "        'float_params':{'tvec__ngram_range':[(1,1),(1,2)],'tvec__use_idf':(True,False)}\n",
    "    },\n",
    "]\n",
    "run_classifiers(classifiers_list,X,y,tfidf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addbe04f",
   "metadata": {},
   "source": [
    "Interesting! In turns out **not** using inverse document frequency gives a better accuracy, albeit an improvement by 0.2% only.  \n",
    "This means, we are using Term Frequency alone without Inverse Document Frequency.  \n",
    "Not surprisingly, a ngram range of 1 to 2 gave better accuracy than 1.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
